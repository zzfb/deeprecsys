{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zhongz/miniconda3/envs/deeprecsys/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Epoch 1/3\n",
      "1/1 [==============================] - 1s 752ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.8000 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 8.0572 - regularization_loss: 0.0000e+00 - total_loss: 8.0572\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 25ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 1.0000 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 8.0022 - regularization_loss: 0.0000e+00 - total_loss: 8.0022\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 26ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 1.0000 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 7.9360 - regularization_loss: 0.0000e+00 - total_loss: 7.9360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 12:37:33.959069: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x31b410a60>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import numpy as np\n",
    "\n",
    "# Create synthetic movie data\n",
    "movies = tf.data.Dataset.from_tensor_slices({\n",
    "    \"title\": [\"Movie \" + str(i) for i in range(5)],\n",
    "    \"genre\": [\"Action\", \"Comedy\", \"Drama\", \"Comedy\", \"Action\"]\n",
    "})\n",
    "\n",
    "# Convert movies dataset to just titles for the candidates\n",
    "movie_titles = movies.map(lambda x: x[\"title\"])\n",
    "\n",
    "# Create synthetic user data\n",
    "users = tf.data.Dataset.from_tensor_slices({\n",
    "    \"user_id\": [str(i) for i in range(3)],\n",
    "    \"age\": [20, 30, 40]\n",
    "})\n",
    "\n",
    "# Define a simple recommendation model\n",
    "class SimpleModel(tfrs.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Compute embeddings for users\n",
    "        self.user_model = tf.keras.Sequential([\n",
    "            # Add +1 to vocabulary size for padding\n",
    "            tf.keras.layers.StringLookup(vocabulary=list([\"0\", \"1\", \"2\"])),\n",
    "            tf.keras.layers.Embedding(4, 32),  # Changed from 3 to 4\n",
    "        ])\n",
    "\n",
    "        # Compute embeddings for movies\n",
    "        self.movie_model = tf.keras.Sequential([\n",
    "            # Add +1 to vocabulary size for padding\n",
    "            tf.keras.layers.StringLookup(vocabulary=list([\"Movie 0\", \"Movie 1\", \"Movie 2\", \"Movie 3\", \"Movie 4\"])),\n",
    "            tf.keras.layers.Embedding(6, 32),  # Changed from 5 to 6\n",
    "        ])\n",
    "\n",
    "        # Task\n",
    "        self.task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=movie_titles.batch(128).map(self.movie_model)\n",
    "        ))\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        movie_embeddings = self.movie_model(features[\"title\"])\n",
    "        \n",
    "        return self.task(user_embeddings, movie_embeddings)\n",
    "\n",
    "# Create synthetic interactions\n",
    "interactions = tf.data.Dataset.from_tensor_slices({\n",
    "    \"user_id\": [\"0\", \"1\", \"2\", \"1\", \"2\"],\n",
    "    \"title\": [\"Movie 0\", \"Movie 1\", \"Movie 2\", \"Movie 3\", \"Movie 4\"]\n",
    "}).batch(32)\n",
    "\n",
    "# Create and train the model\n",
    "model = SimpleModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "# Train for 3 epochs\n",
    "model.fit(interactions, epochs=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeprecsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
